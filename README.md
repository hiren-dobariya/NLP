# NLP
Machine Learning : 
  Supervised
  Unsupervised

  Supervised:
    Classification
    Rregression

Models do not directly understand human language. There are techniques that convert human language into meaningful vectors. This process, where a model takes human language as input and converts it into vectors, is called Natural Language Processing (NLP).
NLP techniques (like tokenization, embeddings, word2vec, transformers, etc.) convert human language into numerical representations (vectors).
These vectors capture meaning and context so the model can process them.

<h3>What is Tokenization?</h3>
<ul>
  <li>Tokenization means splitting text into smaller pieces (called tokens).</li>
  <li>Tokens can be words, characters, or sub-words.</li>
  <li>These tokens are then used by computers (or machine learning models) to understand and process text.</li>
</ul>

<ul>
  <li>Corpus</li>
  <li>Documents</li>
</ul>


<h3>What is Lemmatization?</h3>
Lemmatization is the process of reducing a word to its base form (called lemma) while keeping the meaning correct.
Word: "playing" → Lemma: "play",
Word: "children" → Lemma: "child",
Word: "toys" → Lemma: "toy",






